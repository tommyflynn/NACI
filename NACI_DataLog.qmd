---
title: "Data Log"
author: "Tommy Flynn"
format: 
  html:
    theme: solar
    toc: true
    code-tools: true
    code-fold: true
    code-copy: true
    code-summary: "View Code"
    code-block-bg: true
    code-block-border-left: "#31BAE9"
    number-sections: true
    page-layout: full
---
__Options__

```{r Options}
#| error: false
#| warning: false
#| message: false
# set options
library(knitr)
knitr::opts_chunk$set(root.dir = "~/Documents/1_Research/2_Data_Science/0_Projects/1_NACI/Data",
                      error = TRUE,
                      collapse = TRUE,
                      comment = "#>",
                      tidy = TRUE,
                      tidy.opts = list(width.cutoff = 60),
                      message = FALSE,
                      warning = FALSE,
                      cache = TRUE,
                      cache.lazy = FALSE)
# options(na.action = na.warn)??
```

__Packages__

```{r Packages}
#| message: false
#| warning: false
# ImportingImportingImportingImportingImportingImportingImportingImporting
library(readr)
library(haven)
library(readxl) # UNUSED: library(httr) # library(googlesheets4) # library(googledrive) # library(rvest) # library(jsonlite) # library(xml2) # library(bigrquery) # library(DBI) # library(rgdal) # library(maptools)
# WranglingWranglingWranglingWranglingWranglingWranglingWranglingWranglingWrangling 
library(tidyverse)
library(tibble)
library(labelled)
library(forcats)
library(stringr)
library(lubridate) # UNUSED: library(anytime) # library(hms)
# AnalyzingAnalyzingAnalyzingAnalyzingAnalyzingAnalyzingAnalyzingAnalyzingAnalyzing 
library(gtsummary)
library(xtable) # UNUSED: # library(ztable) # library(sjmisc) # library(psych) # library(memisc) # library(quantreg) # UNUSED: Networks: # library(igraph), # library(networkDynamic) # UNUSED: Models: # library(modelr) # library(corrr) # UNUSED:Time-Series # library(tseries) # library(xts) # UNUSED: Spatio-temporal: # UNUSED: library(spacetime) # library(leaflet) # library(rgdal) # library(maptools)
# ProgrammingProgrammingProgrammingProgrammingProgrammingProgrammingProgrammingProgramming
library(purrr) # UNUSED: # library(magrittr) # library(glue)
# FormattingFormattingFormattingFormattingFormattingFormattingFormattingFormattingFormatting 
library(quarto)
library(printr)
library(knitr)
library(kableExtra)
library(htmltools)
library(gt)
library(pander)
library(bibtex)
library(RefManageR)
```

# Data importing  

Get the path pointing to the directory where data are stored  (i.e., "/[project directory]/Data"). Then print a list of files with `list.files` using that object as the `path` argument.  

```{r Data_Directory}
data_path <- paste(getwd(), "Data", sep = "/")

# 1.  create (but don't print) a list of files stored in the "Data" directory
all_data_fullpaths <- list.files(path = data_path,
                                     full.names = TRUE)

all_data_filenames <- lst(All_Files = list.files(path = data_path,
                                     full.names = FALSE))
# all_data_filenames

# Create and print lists of only .sas7bdat (SAS) data  files
sas_data_fullpaths <- list.files(path = data_path,
                             pattern = "*.sas7bdat",
                             full.names = TRUE)
sas_data_filenames <- lst(SAS_Files = list.files(path = data_path,
                                     pattern = "*.sas7bdat",
                                     full.names = FALSE))


# Create and print list of only .xlsx and .xls (Excel)  files [NONE]
# xlsx_data_fullpaths <- list.files(path = data_path,
#                              pattern = "*.xls",
#                              full.names = TRUE)
# xlsx_data_filenames <- lst(XL_Files = list.files(path = data_path,
#                                      pattern = "*.xls",
#                                      full.names = FALSE))
# xlsx_data_filenames
# Create and print list of only .txt file names [NONE]
# txt_data_fullpaths <- list.files(path = data_path,
#                              pattern = "*.txt",
#                              full.names = TRUE)
# txt_data_filenames <- lst(TXT_Files = list.files(path = data_path,
#                                      pattern = "*.txt",
#                                      full.names = FALSE))
# txt_data_filenames

# Create and print list of all .csv file paths and  files names
# csv_data_fullpaths <- list.files(path = data_path,
                             # pattern = "*.csv",
                             # full.names = TRUE)
# csv_data_filenames <- lst(CSV_Files = list.files(path = data_path,
                                     # pattern = "*.csv",
                                     # full.names = FALSE))
# csv_data_filenames
```

__What _data files_ are in "/Data"?__

```{r}
tibble(`All Files in "/Data"` = all_data_filenames[[1]])
```



__Print a list of only SAS files in "/Data"?__  

```{r}
tibble(`SAS Files in "/Data"` = sas_data_filenames[[1]])
```

# IDs & SIDs

Read & print data from the following files: 

* "finalsids6944.sas7bdat"

* "id_sid_matchup.sas7bdat"

* "id_sid_matchup.sas7bdat"

```{r id_sid_matchup}
# 1d. "id_sid_matchup2.sas7bdat" has the same variables as "id_sid_matchup.sas7bdat", so only need id_sid_mathcup2
id_sid_matchup <- read_sas(paste(data_path, "id_sid_matchup.sas7bdat", sep = "/"))
id_sid_matchup2 <- read_sas(paste(data_path, "id_sid_matchup2.sas7bdat", sep = "/"))
# Check these to see if they share columns
# id_sid_matchup %in% id_sid_matchup2
# id_sid_matchup2 %in% id_sid_matchup
# What variables (columns) does id_sid_matchup2 have that the other does not?
# names(id_sid_matchup2[-(id_sid_matchup %in% id_sid_matchup2)])
# Import ID 
ids_final <- read_sas(paste(data_path, "finalsids6944.sas7bdat", sep = "/"))

generate_dictionary(id_sid_matchup2)
generate_dictionary(ids_final)
# save(ids_final, file = "Data/ids_final.Rdata")
# save(id_sid_matchup2, file = "Data/id_sid_matchup2.Rdata")
```


# Patient Data  

List other "patient" data files:

```{r}
patient_filepaths <- paste(data_path, 
                         "SAS_data_files/patient_data_files", 
                         sep = "/")
patient_filenames <- lst(Patient_Files = list.files(patient_filepaths))
tibble(`Patient Files` = patient_filenames[[1]])
```

## Patient Demographics

Demographic information with EHR numbers and encounter numbers. Note that **EHR numbers may repeat!**

```{r Demographics}
demographic_df <- read_csv(paste0(data_path, "/Population_Patient_Demographics.csv"))
# glimpse(demographic_df)
demographic_df <- demographic_df %>% 
  mutate(ED_arr = mdy(`ED Arrival Timestamp`), 
         ED_dep = mdy(`ED Departure Timestamp`),
         med_rec_no = as.character(`Medical Record Number`),
         encounter_no = as.character(`Enc .`),
         # .before = 1,
         across(!where(is.Date)
                & !where(is.double)
                & !where(is.integer)
                & !med_rec_no
                & !encounter_no
                & !`ED Arrival Timestamp`
                & !`ED Departure Timestamp`
                & !`Chief Complaint`
                & !`% ED Patients Admitted as Inpt or Obs`, 
                .fns = as_factor))

# Print dictionary of patient demographic data
generate_dictionary(demographic_df)
# save(demographic_df, file = "Data/demographic_df.Rdata")
```

## Patient Location

The SAS data file, "completepat.sas7bdat," contains RFID badge location (by *room number*) for all patients each second of every shift. The data were stored in a table that is extremely **wide**. 

I used `pivot_longer()` to reshape it by collapsing all location-by-second columns (variables `flocX`, where `X` is the shift time in seconds that the respective SID was identified in room number `flocX`) into two columns, names set to `seconds` and values to `location`. Note that this creates **many duplicated rows** (i.e., needs filtering).

```{r pt_complete}
pt_complete <- read_sas(paste(data_path, "completepat.sas7bdat", sep = "/"))
# 1. subset a random sample of 30 observations for data transformation code preparation
set.seed(711)
pt_complete_sample <- pt_complete %>% slice_sample(n = 30)
pt_complete_sample <- pt_complete_sample %>% 
# 2. Pivot the data.frame from wide to long by placing all column names that start with "floc" into a new column, "seconds," and placing respective observations for each "floc" variable into a "location_num" column
  pivot_longer(cols = starts_with("floc"), 
               names_to = "seconds", 
               values_to = "location_num")
               # values_drop_na = TRUE) # %>% 
# 3b. Delete the prefix "floc" from `seconds` and change class to numeric
  # mutate(seconds = as.integer(str_replace(seconds, "floc", "")), 
  #        shift_num_ampm = str_trim(shift_num_ampm),
  #        shift_num = as.integer(str_extract(shift_num_ampm, "[:digit:]+")),
  #        am_pm = str_extract(shift_num_ampm, "am|pm"),
  #        date = make_date(year = year, month = mon, day = day))
# 4. Filter out all rows for which no location was recorded
  # filter() (STILL NEED TO DO THIS)
# 3. View data frame dictionary  
generate_dictionary(pt_complete_sample)

```


# Staff Data

List of other staff data files (`.sas7bdat`):

```{r}
staff_filepaths <- paste(data_path, 
                         "SAS_data_files/staff_data_files", 
                         sep = "/")
staff_filenames <- lst(Staff_Files = list.files(staff_filepaths))
tibble(`Staff Files` = staff_filenames[[1]])
```

## Staff location data

The SAS data file, "completestaff.sas7bdat," contains RFID badge location (by *room number*) for all staff each second of every shift.

```{r}
#| eval: false  
# 1. pull "completestaff.sas7bdat" from `sas_data_list` as `tibble()` 
staff_complete <- read_sas(paste(data_path, "completestaff.sas7bdat", sep = "/"))
# Subset a random sample of 30 observations
set.seed(321)
staff_complete_sample <- staff_complete %>% slice_sample(30)
# 2. Use a random sample of staff_complete for data cleaning & transformation 
staff_complete_sample <- staff_complete_sample %>% 
  # 2a. Pivot the data.frame from wide to long by placing all column names that start with "floc" into a new column, "seconds," and placing respective observations for each "floc" variable into a "location_num" column
  pivot_longer(cols = starts_with("floc"), 
               names_to = "seconds", 
               values_to = "location_num",
               values_drop_na = TRUE) # %>% 
  # 2b. Remove the prefix "floc" from `time_seconds` and keep the digits as `seconds`
  # mutate(seconds = as.integer(str_replace(seconds, "floc", "")), 
         # shift_num_ampm = str_trim(shift_num_ampm),
         # shift_num = as.integer(str_extract(shift_num_ampm, "[:digit:]+")),
         # am_pm = str_extract(shift_num_ampm, "am|pm"),
         # date = make_date(year = year, month = mon, day = day)) # %>% 
  # 2c. Filter out all rows for which no location was recorded
  # filter(!is.na(location))

# 3. View data frame structure
generate_dictionary(staff_complete_sample)
```

# Network Data

## Event Files

__List all event files__

```{r}
event_filepaths <- paste(data_path, 
                         "SAS_data_files/event_data_files", 
                         sep = "/")
event_filenames <- lst(Event_Files = list.files(event_filepaths))
tibble(`Event Files` = event_filenames[[1]])
```

## Network Files

__List all network data files:__


```{r}
net_filepaths <- paste(data_path, 
                         "SAS_data_files/network_data_files", 
                         sep = "/")
net_filenames <- lst(Net_Files = list.files(net_filepaths))
tibble(`Network Files` = net_filenames[[1]])
```



# SessionInfo

```{r SessionInfo}
#| echo: false
sessioninfo::session_info()%>%
  details::details(
    summary = 'Current session info',
    open    = FALSE
  )
```
